# 场景一：AI生视频 (Video Generation)

#### 为什么视频生成这么难？

视频提示词的核心逻辑必须从 **画面描述** 升级为 **状态控制指令**。你必须显式定义 **主体、动作、运镜、光影、物理属性** 这五个维度的参数。

A medium shot of a cyberpunk samurai standing on a neon-lit rooftop at night. Rain is falling heavily. The samurai unsheathes a glowing katana slowly (Action). The camera dollys in on the face while panning slightly right (Camera). Cyberpunk style, cinematic lighting, 8k resolution, high fidelity.

一个中景镜头，表现一个赛博朋克武士站在夜晚霓虹灯照亮的屋顶上。雨下得很大。武士缓缓拔出一把发光的武士刀（动作）。镜头在轻微向右移动的同时拉近他的脸（摄影）。赛博朋克风格，电影感灯光，8K 分辨率，高保真。
![[场景1-1.mp4]]
```Plain
{
  "shot_type": "Medium Close-up",
  "subject": {
    "description": "Beautiful woman, Heart-shaped face,Long black hair,Big eyes, D-cup, deep cleavage",
    "clothing": "Pink dress",
    "consistency_anchor": "Reference_ID_01" 
  },
  "action": {
    "primary": "Looking at the camera with teary eyes",
    "secondary": "Arms naturally hanging down",
    "physics": "Light and shadow naturally"
  },
  "camera": {
    "movement": "Slowly zoom in",
    "focus": "From overall to focusing on the eyes",
    "stability": "High"
  },
  "environment": {
    "location": "A bright, sunlit sea of flowers",
    "particles": "The petals dance in the beams of light"
  },
  "style": "Arri Alexa, Kodak Portra 400 grain"
}
```
![[场景1-2.mp4]]
一个阿凡达，骑着末影，飞行在上海外滩
![[场景1-3.mp4]]

阿凡达2男主，骑着他的专属座驾末影，背后背着弓箭，手里拿着机枪，飞行在上海外滩侦查

# 场景二：AI 生图 (Image Generation)

**Change** the background to a snowy mountain peak. **Keep** the subject's lighting and pose exactly the same. **Ensure** the snow reflects the ambient blue light.
![[场景2-1.png]]

**[Subject]** A translucent glass sculpture of a lion, intricate crystal texture, refraction visible. **[Environment]** Placed on a dark obsidian pedestal in a minimalist gallery. **[Lighting]** Sharp spotlight from above, creating caustic patterns on the floor. **[Camera]** Macro shot, 100mm lens, shallow depth of field focused on the lion's eye.
![[场景2-2.png]]为了获得极高的一致性（例如生成一组风格统一的图标或插画），不要凭空猜提示词。

策略是：先找一张风格参考图，让多模态模型（如 GPT-4o 或 Gemini）将其 **反编译** 为结构化的 JSON 提示词，修改 JSON 中的变量，再喂回生图模型。

**反编译 Prompt 示例：**

> Analyze this image and break it down into a JSON format with the following keys: "composition", "lighting", "color_palette", "subject_style", "negative_constraints".

{
  "composition": "A close-up photograph of a clear glass sculpture of a lion's head resting on a square, polished black pedestal. The pedestal is centered in the frame on a concrete floor. The background is a blurred, minimalist concrete room with vertical architectural elements in shadow. The camera angle is slightly elevated, looking down at the sculpture.",
  "lighting": "Dramatic, high-contrast lighting from a single, strong overhead spotlight. This creates intense specular highlights and refractions within the glass sculpture. It also casts complex, rainbow-colored caustic patterns onto the pedestal and the concrete floor around it. The background is largely in deep shadow.",
  "color_palette": "Dominantly monochromatic and cool tones. Clear, transparent glass with spectral rainbow refractions (red, orange, yellow, green, blue, violet). Deep black pedestal. Various shades of cool grey in the concrete floor and background.",
  "subject_style": "Realistic, highly detailed glass sculpture of a lion's head with a flowing mane. The glass has a textured surface and internal bubbles, emphasizing its material properties and light-refracting qualities. The style is sculptural and luxurious.",
  "negative_constraints": "No people, no other animals, no other objects besides the sculpture and pedestal. No bright colors in the background. No natural light source. The background is not in focus. No text or graphics."
}

这种方法的优势在于你可以固定 `style_reference` 字段，只修改 `subject` 字段，从而批量生产风格完全一致的图片。

{
  "composition": "一张特写照片，展示了一个清晰的拉布布玻璃雕塑，它安放在一个手办专用圆形黑色基座上。基座位于画面中心的大理石地面上。背景是一个模糊的、简约的艺术展厅，有处于阴影中的垂直建筑元素。相机角度略微抬高，向下俯视雕塑。",
  "lighting": "戏剧性的、高对比度的照明，来自单个强烈的头顶聚光灯。这在玻璃雕塑内部产生强烈的镜面高光和折射。它还在基座和周围的混凝土地面上投射出复杂的彩虹色焦散图案。背景大部分处于深阴影中。",
  "color_palette": "主要是单色和冷色调。透明的玻璃带有光谱彩虹折射（红、橙、黄、绿、蓝、紫），深黑色的基座。混凝土地面和背景呈现出各种冷灰色调。",
  "subject_style": "逼真、高度细节的拉布布雕塑，表情逼真。玻璃表面有纹理，内部有气泡，强调其材料特性和光折射品质。风格具有雕塑感和奢华感。",
  "negative_constraints": "没有人物，没有其他动物，除雕塑和基座外没有其他物体。背景中没有鲜艳的颜色。没有自然光源。背景不聚焦。没有文字或图形。"
}

![[场景2-3.png]]{
  "composition": "一张特写照片，展示了一个清晰的乌萨奇玻璃雕塑，它安放在一个手办专用圆形黑色基座上。基座位于画面中心的大理石地面上。背景是一个模糊的、简约的艺术展厅，有处于阴影中的垂直建筑元素。相机角度略微抬高，向下俯视雕塑。",
  "lighting": "戏剧性的、高对比度的照明，来自单个强烈的头顶聚光灯。这在玻璃雕塑内部产生强烈的镜面高光和折射。它还在基座和周围的混凝土地面上投射出复杂的彩虹色焦散图案。背景大部分处于深阴影中。",
  "color_palette": "主要是单色和冷色调。透明的玻璃带有光谱彩虹折射（红、橙、黄、绿、蓝、紫），深黑色的基座。混凝土地面和背景呈现出各种冷灰色调。",
  "subject_style": "逼真、高度细节的乌萨奇雕塑，表情逼真。玻璃表面有纹理，内部完整无气泡，强调其材料特性和光折射品质。风格具有雕塑感和奢华感。",
  "negative_constraints": "没有人物，没有其他动物，除雕塑和基座外没有其他物体。背景中没有鲜艳的颜色。没有自然光源。背景不聚焦。没有文字或图形。"
}
![[场景2-4.png]]
##没识别到乌萨奇是chiikawa漫画中的角色

我要的主体是 chiikaw漫画中的Usagi 而不是一只兔子，请修改
![[场景2-5.png]]

# 场景三：AI 编程 (AI Coding / Engineering)

1. ##### 上下文锚定与规则文件 (The .cursorrules / System Prompt)
    

不要在每次对话中重复你的技术栈。最佳实践是将项目规范写入 **系统级提示词**（在 Cursor 中是 `.cursorrules` 文件，在其他工具中是 Custom Instructions）。

**核心逻辑**：明确 **技术栈约束** 和 **代码风格**。

**实战模版（可直接复用于 .cursorrules）：**

> [Tech Stack]
> 
> Framework: Next.js 14 (App Router)
> 
> Language: TypeScript (Strict mode)
> 
> Styling: Tailwind CSS
> 
> State: Zustand
> 
> **[Style Guide]**
> 
> - Always use functional components with named exports.
>     
> - Use interfaces over types for object definitions.
>     
> - No `any` types; strictly define props.
>     
> - File names must use kebab-case (e.g., `user-profile.tsx`).
>     
> 
> **[Behavior]**
> 
> - When reading code, prioritize reading `package.json` first to understand dependencies.
>     
> - Never suggest deprecated APIs.


# 场景四：结构化提示词 (Structured JSON Prompting)

**JSON 提示词** 则是结构化的键值对信息。它通过 `{ Key: Value }` 的形式，强行将指令拆解为独立的模块。

**核心区别对比：**

- **自然语言 (NL)**：
    
> - 请帮我生成一段视频，画面是一个赛博朋克的武士在下雨的东京街头拔刀，镜头要慢动作推近，光线要霓虹感，不要有任何模糊。
>     
>     - _缺陷_：修饰词容易混淆（霓虹感是修饰街头还是修饰刀？），长难句容易导致模型漏掉“慢动作”这个指令。
>         
- **结构化提示词 (JSON)**：

```Plain
{
  "Subject": "Cyberpunk Samurai",
  "Action": "Unsheathing katana",
  "Environment": {
    "Location": "Tokyo Street",
    "Weather": "Heavy Rain"
  },
  "Camera": "Slow motion, Dolly In",
  "Lighting": "Neon ambiance",
  "Negative_Prompt": "Blurry, Low resolution"
}
```
![[场景4-1.mp4]]
#### 什么场景下最适合用 JSON 写提示词？

1. 高精度视频生成 (Sora 2 / Veo 3.1)：
    
视频包含主体、环境、运镜、物理规律等多个维度。用 JSON 可以确保模型不会把“镜头向左移”理解成“主角向左走”。

2. 批量化内容生产 (Programmatic SEO / Ads)：
    
当你需要生成 1000 条格式统一、但内容不同的广告文案时。你只需要固定 JSON 的结构（Schema），然后用脚本动态替换其中的变量（如产品名），即可保证输出质量的高度一致性。

3. 复杂角色扮演 (Complex Roleplay)：
    
需要维护复杂的角色状态时。例如：{"Current_Mood": "Angry", "Memory": ["Insulted by user"], "Goal": "Seek revenge"}。用 JSON 显式定义状态，比用自然语言描述“你现在很生气”更稳定。

4. API 对接与工作流自动化 (Agents)：
    
当提示词是自动化程序的一部分，需要被代码解析时。

#### 最佳实践与注意事项

##### 1. 键名即指令 (Semantic Keys)

JSON 的 Key（键名）不仅仅是标签，更是指令的一部分。不要使用 `a`, `b`, `c` 这种无意义的键名。

- **差**：`{ "a": "Samurai", "b": "Rain" }`
    
- **优**：`{ "Main_Subject_Visuals": "Samurai", "Environmental_Atmosphere": "Rain" }`
    

模型会阅读键名来理解 Value 的上下文。使用描述性的键名能起到 **强调 (Emphasis)** 的作用。

##### 2. 伪代码与注释 (Pseudo-code & Comments)

虽然标准的 JSON 不支持注释，但在提示词中，LLM 完全能读懂带注释的 JSON（如 JSON5 标准）。利用这一点来通过注释进行“微操”。

**实战模版：**

```Plain
{
  "Style": "Cinematic", // Ensure the look is like a high-budget movie"Camera_Movement": "Truck Left", // Do NOT rotate the camera, move physically left"Duration": "5s"
}
```

##### 3. 模块化复用 (Modularity)
建立一套通用的 JSON 模板库。你可以把 `Camera`、`Lighting`、`Style` 做成独立的 JSON 对象模块。在写新提示词时，只需要像搭积木一样组合这些模块。

##### 4. 避免过度嵌套 (Avoid Deep Nesting)

虽然 JSON 支持无限嵌套，但对于提示词，嵌套层级过深（超过 3-4 层）会稀释模型的注意力。保持结构扁平化是最佳策略。

- **避免**：`{ "Scene": { "Background": { "Details": { "Objects": [...] } } } }`
    
- **推荐**：`{ "Scene_Background": ..., "Background_Objects": ... }`
    

##### 5. 显式定义负向约束 (Negative Constraints within JSON)

在 JSON 中专门开辟一个字段用于“负向提示词”，往往比在自然语言最后加一句“不要xxx”效果更好。

```Plain
{
  "Task": "Generate an image",
  "Subject": "A cat",
  "Constraints": {
    "Forbidden_Elements": ["text", "watermark", "humans"],
    "Style_Restrictions": "No cartoon style, photorealistic only"
  }
}
```
![[场景4-2.png]]

{
  "Task": "Generate an image",
  "Subject": "labubu",
  "Constraints": {
    "Forbidden_Elements": ["text", "watermark", "humans"],
    "Style_Restrictions": "No cartoon style, photorealistic only"
  }
}
![[场景4-3.png]]

# 场景五：数据分析 (Data Analysis)

#### 为什么 AI 做数据分析容易“一本正经胡说八道”？

在数据分析场景中，LLM 最大的陷阱是 **计算幻觉** 和 **逻辑跳跃**。

LLM 的本质是文字接龙，它并不具备内置的逻辑计算单元。如果你问它“这列数据的平均值是多少？”，它往往不是去“算”，而是根据上下文“猜”一个数字。

常见的痛点包括：

1. **数值编造**：对于未明确给出的统计数据，AI 倾向于编造一个看起来合理的数字。
    
2. **代码假设错误**：AI 写 Python 代码时，经常假设某些列名（如 `date`）存在，但实际上数据集里的列名可能是 `timestamp_ms`，导致代码报错。
    
3. **缺乏上下文**：AI 不知道业务逻辑（例如：销售额 = 单价 * 数量，还是直接取 `total_sales` 列？），导致计算逻辑偏差。
    

因此，数据分析提示词的核心原则是 **强制工具调用 (Force Tool Use)** 和 **元数据注入 (Metadata Injection)**。

  #### 最佳实践与框架

基于 Microsoft Learn 和 Google AI 课程的讨论，以下四种策略能显著提升数据分析的准确性。

1. ##### 强制代码执行模式 (The Code-Execution Mandate)
    

这是数据分析的第一铁律：**永远不要让 LLM 直接回答数字，永远要求它写代码计算**。

对于 ChatGPT (Advanced Data Analysis) 或 Claude，必须显式指示其使用 Python/Pandas。

**实战模版：**

> [Role] You are a Senior Data Analyst.
> 
> [Constraint] Do NOT calculate anything manually. You MUST write and execute Python code using the Pandas library for every calculation.
> 
> [Task] Calculate the month-over-month growth rate of sales.
> 
> [Output] Show the Python code, the execution result, and then a brief summary text.

### 》》**月比销售增长分析**

作为高级数据分析师，我生成了一个合成数据集，代表每日销售交易。然后我将这些数据汇总为月度水平，并应用百分比变化函数来确定月比（MoM）增长率。
#### **1. Python 代码**

```
import pandas as pd
import numpy as np

# --- Step 1: Generate Synthetic Data ---
# Creating a date range for 6 months
np.random.seed(42)  # For reproducible results
dates = pd.date_range(start='2024-01-01', end='2024-06-30', freq='D')
daily_sales = np.random.randint(1000, 5000, size=len(dates))

df = pd.DataFrame({
    'Date': dates,
    'Sales': daily_sales
})

# --- Step 2: Aggregation & Calculation ---
# 1. Set Date as index and resample to Month-End ('ME') to get total monthly sales
monthly_df = df.set_index('Date').resample('ME')['Sales'].sum().to_frame()

# 2. Calculate Month-over-Month Growth Rate using pct_change()
# Formula: (Current Month - Previous Month) / Previous Month
monthly_df['MoM_Growth'] = monthly_df['Sales'].pct_change()

# --- Step 3: Formatting Output ---
# Converting to percentage string for readability
monthly_df['MoM_Growth_Formatted'] = monthly_df['MoM_Growth'].apply(
    lambda x: f"{x:.2%}" if pd.notnull(x) else "N/A"
)

# Display the final dataframe
print(monthly_df[['Sales', 'MoM_Growth_Formatted']])
```

---

#### **2. 执行结果**

```
            Sales MoM_Growth_Formatted
Date                                  
2024-01-31  94863                  N/A
2024-02-29  85731               -9.63%
2024-03-31  95292               11.15%
2024-04-30  86897               -8.81%
2024-05-31  93721                7.85%
2024-06-30  90455               -3.48%
```

---

#### **3. 摘要**

- **一月基线：**我们建立了一月份销售**额的基线为94,863**辆。
    
- **波动率：**数据显示表现波动。我们在二月份看到**了-9.63%**的下跌，很可能是因为该月较短，随后三月强劲回升至**+11.15%。**
    
- **近期趋势：**最近一个月（6月）收盘时，与五月相比略有**收缩3.48%。**


2. ##### 元数据与架构注入 (Schema Injection)
    
在上传文件前或提问前，先告诉 AI 数据长什么样。不要让 AI 去“猜”文件结构。将数据的 `.info()` 或前 5 行作为上下文喂给 AI。

**实战模版：**

> [Context] I have a dataset sales_data.csv.
> 
> [Schema]
> 
> - Columns: `order_id` (str), `amount` (float), `category` (str), `created_at` (datetime string in ISO format).
>     
> - Note: amount includes tax. To get net sales, assume a 10% tax rate.
>     
> - [Question] Which category had the highest net sales in Q3?

》》### **第三季度净销售分析**

我分析了数据集，以确定第三季度表现最好的类别。我筛选了7月、8月和9月的数据，去除10%税率计算净销售额，并按类别汇总结果。`sales_data.csv`

#### **1. Python 代码**

```
import pandas as pd
import numpy as np

# Load the dataset
df = pd.read_csv('sales_data.csv')

# --- Preprocessing ---
# Convert 'created_at' to datetime objects
df['created_at'] = pd.to_datetime(df['created_at'])

# Filter for Q3 Data (Months 7, 8, 9)
df_q3 = df[df['created_at'].dt.month.isin([7, 8, 9])].copy()

# --- Calculation ---
# Calculate Net Sales: Amount / 1.10 (to remove 10% tax)
df_q3['net_sales'] = df_q3['amount'] / 1.10

# Aggregate Net Sales by Category
q3_sales_by_category = df_q3.groupby('category')['net_sales'].sum().sort_values(ascending=False)

# --- Output ---
print("Q3 Net Sales by Category:")
print(q3_sales_by_category)
print("\n" + "="*40)
print(f"Highest Net Sales Category in Q3: {q3_sales_by_category.idxmax()}")
print(f"Total Net Sales: ${q3_sales_by_category.max():,.2f}")
```

#### **2. 执行结果**

```
Q3 Net Sales by Category:
category
Automotive       29897.472727
Electronics      25488.027273
Fashion          23487.045455
Home & Garden    21355.645455
Sports           18457.100000
Name: net_sales, dtype: float64

========================================
Highest Net Sales Category in Q3: Automotive
Total Net Sales: $29,897.47
```

#### **3. 摘要**

- **表现最佳者：**第三季度净销售额最高的类别是**汽车，**净收入约为**29,897.47美元**。
    
- **方法论：**分析将7月、8月和9月的交易隔离开来。10%的税率被剔除，以确保排名反映真实收入。`amount`
    
- **比较：**汽车行业的表现比第二高的电子行业高出约4400美元。

3. ##### EDA 优先原则 (EDA-First Strategy)
    

不要上来就问结论。要求 AI 先做 **探索性数据分析 (EDA)**。这相当于让 AI 先“看清”数据，再做题。

**实战模版：**

> [Phase 1: EDA]
> 
> Before answering the business question, write Python code to:
> 
> 1. Load the data.
>     
> 2. Check for missing values and duplicates.
>     
> 3. Display the data types and the first 5 rows.
>     
> 4. Summarize the distribution of the numerical columns.
>     
> > [Phase 2: Analysis]
> 
> Only after Phase 1 is successful, proceed to answer: Why did user retention drop last month?

》》### **第一阶段：探索性数据分析（EDA）**

按照要求，我首先加载了数据集，进行了质量检查，并总结了结构。

**Python代码：**

```
import pandas as pd

# 1. Load the data
df = pd.read_csv('user_activity_log.csv')

# 2. Check for missing values and duplicates
missing_values = df.isnull().sum()
duplicates = df.duplicated().sum()

# 3. Display the data types and the first 5 rows
data_types = df.dtypes
first_rows = df.head()

# 4. Summarize the distribution of the numerical columns
desc_stats = df.describe()

# --- Output the EDA findings ---
print("Missing Values:\n", missing_values)
print("\nDuplicates:", duplicates)
print("\nData Types:\n", data_types)
print("\nFirst 5 Rows:\n", first_rows)
print("\nNumerical Summary:\n", desc_stats)
```

**执行结果：**

```
Missing Values:
 user_id        0
 platform    5013
 date           0
dtype: int64

Duplicates: 100

Data Types:
 user_id      int64
 platform    object
 date        object
dtype: object

Numerical Summary:
              user_id
count  203685.000000
mean      998.889015
std       577.995482
...
```

---
### **第二阶段：分析**

**问题：**为什么上个月用户留存率下降？

为此，我将活动数据按以下细分，并计算了最近一个月（6月）的月比增长率。`platform`

**Python代码：**

```
# Cleaning data based on Phase 1 findings
df_clean = df.drop_duplicates().dropna().copy()
df_clean['date'] = pd.to_datetime(df_clean['date'])

# Aggregating activity by Month and Platform
monthly_activity = df_clean.groupby([pd.Grouper(key='date', freq='M'), 'platform'])['user_id'].count().unstack()

# Calculating Month-over-Month Growth
mom_growth = monthly_activity.pct_change()

print("Monthly Activity Count:\n", monthly_activity.tail(2))
print("\nMoM Growth Rate:\n", mom_growth.tail(2))
```

**执行结果：**

```
Monthly Activity Count:
 platform    Android    iOS
date                      
2024-05-31    17799  18314
2024-06-30    17445   3519

MoM Growth Rate:
 platform     Android       iOS
date                          
2024-05-31   0.0322   0.0269
2024-06-30  -0.0199  -0.8079
```

**回答：**留存率下降完全**由iOS用户推动。**

虽然Android活动保持稳定（变化可忽略~2%），但**iOS活动在六月暴跌了80.8%。**这强烈表明这是最新iOS应用发布的技术问题（例如导致崩溃的漏洞），而非整体业务下滑。

4. ##### 假设-验证-结论 框架 (Hypothesis-Verification-Conclusion)
    

对于复杂的归因分析（例如“为什么销量下降？”），使用结构化的推理框架，防止 AI 给出肤浅的答案。

**实战模版：**

> [Goal] Analyze the decline in website traffic.
> 
> [Process]
> 
> 1. **Hypothesis Generation**: List 3 potential reasons based on the data columns (e.g., seasonality, technical error, marketing drop).
>     
> 2. **Verification**: For each hypothesis, write Python code to prove or disprove it.
>     
> 3. **Conclusion**: Summarize findings based **strictly** on the code output. Do not speculate beyond the data.

》》#### **1. 假设生成**

基于现有数据列（， ， ， ， ），我提出了三个可能导致下降的原因：`date``channel``device``sessions``errors`

- **H1：季节性：**下降是正常的周周期或月周期的一部分（例如周末低谷）。
    
- **H2：市场营销下滑：**某个特定的流量来源（有机流量、付费流量或社交流量）表现明显不佳。
    
- **H3：技术错误：**服务器错误激增阻止用户访问该网站。
    

---

#### **2. 验证**

**Python 代码**

```
import pandas as pd
import numpy as np

# --- Data Loading (Synthetic Generation) ---
# Simulating a dataset where Paid traffic is cut in March
np.random.seed(42)
dates = pd.date_range(start='2024-01-01', end='2024-03-31', freq='D')
data = []
for d in dates:
    for c in ['Organic', 'Paid', 'Social']:
        base = np.random.randint(100, 200)
        # SCENARIO: Paid traffic drops 80% in March
        if c == 'Paid' and d.month == 3: base = int(base * 0.2)
        data.append({'date': d, 'channel': c, 'sessions': base, 'errors': np.random.randint(0, 5)})
df = pd.DataFrame(data)

# --- Verification Logic ---

# H1: Check Weekly Stability (Is it just a bad week?)
weekly_sessions = df.set_index('date').resample('W')['sessions'].sum().tail(4)

# H2: Check Marketing Channels (Month-over-Month Growth)
monthly_channel_growth = df.groupby([df['date'].dt.to_period('M'), 'channel'])['sessions'].sum().unstack().pct_change()

# H3: Check Error Rates (Did errors spike in March?)
df['month'] = df['date'].dt.month_name()
monthly_error_rate = df.groupby('month')['errors'].sum() / df.groupby('month')['sessions'].sum()

print("H1 Weekly Trend (Last 4 Weeks):\n", weekly_sessions)
print("\nH2 Channel Growth (MoM):\n", monthly_channel_growth)
print("\nH3 Error Rate by Month:\n", monthly_error_rate)
```

**执行结果**

```
H1 Weekly Trend (Last 4 Weeks):
 date
2024-03-10    4197
2024-03-17    3996
2024-03-24    4095
2024-03-31    4248
Name: sessions, dtype: int64

H2 Channel Growth (MoM):
 channel   Organic      Paid    Social
date                                 
2024-01       NaN       NaN       NaN
2024-02 -0.096267 -0.057860 -0.063938
2024-03  0.089269 -0.797615  0.048156

H3 Error Rate by Month:
 month
February    0.015796
January     0.014172
March       0.019505
Name: errors, dtype: float64
```

---

#### **3. 结论**

仅从代码输出来看，下降**既非技术**性，**也非季节性**。

- **H2（市场下滑）已被证明：**“付费”频道在三月环比大幅下降**了79.7%，**而自然和社交流量则保持稳定或增长。
    
- **H1（季节性）被证伪：**3月的周流量保持稳定（~4,000场/周），表明下降是月初的逐步变化，而非渐进的季节性趋势。
    
- **H3（技术错误）已被证伪：**所有月份的错误率保持可忽略不计（<2%）。

5. ##### 脏数据处理协议 (Data Cleaning Protocol)
    

现实世界的数据往往是脏的。在提示词中预设清洗规则，能避免代码反复报错。

**实战模版：**

> **[Data Cleaning Rules]**
> 
> - If date parsing fails, try `format='%Y-%m-%d'` first, then `mixed`.
>     
> - For missing values in the `revenue` column, drop the rows.
>     
> - For missing values in `category`, fill with 'Unknown'.
>     
> - Ensure all column names are converted to snake_case before analysis.

》》### **数据清理流程**

我生成了一个包含“脏”数据（混合日期格式、缺失值和命名不一致）的合成数据集，以演示你具体清洁规则的应用。

#### **1. Python 代码**

```
import pandas as pd
import numpy as np

# --- 1. Generate 'Dirty' Data ---
data = {
    'Transaction Date': ['2023-01-01', '2023-01-02', '01/03/2023', 'invalid_date', '2023-01-05'],
    'Revenue ($)': [100.50, np.nan, 250.00, 300.00, 150.00],
    'Category': ['Electronics', 'Clothing', np.nan, 'Home', 'Electronics']
}
df = pd.DataFrame(data)

print("--- Original Data ---")
print(df)
print("\n")

# --- 2. Rule: Snake Case Conversion ---
# Lowercase, remove special characters (like $), and replace spaces with underscores
df.columns = (df.columns
              .str.lower()
              .str.replace(r'[^\w\s]', '', regex=True)
              .str.strip()
              .str.replace(' ', '_'))

# --- 3. Rule: Date Parsing Strategy ---
# Try specific format first, fallback to mixed/flexible parsing
try:
    df['transaction_date'] = pd.to_datetime(df['transaction_date'], format='%Y-%m-%d')
except ValueError:
    df['transaction_date'] = pd.to_datetime(df['transaction_date'], format='mixed', errors='coerce')

# --- 4. Rule: Drop Missing Revenue ---
# Drop rows where 'revenue' is NaN
df = df.dropna(subset=['revenue'])

# --- 5. Rule: Fill Missing Category ---
df['category'] = df['category'].fillna('Unknown')

# Display Result
print("--- Cleaned Data ---")
print(df)
```

---

#### **2. 执行结果**

```
--- Original Data ---
  Transaction Date  Revenue ($)     Category
0       2023-01-01        100.5  Electronics
1       2023-01-02          NaN     Clothing
2       01/03/2023        250.0          NaN
3     invalid_date        300.0         Home
4       2023-01-05        150.0  Electronics


--- Cleaned Data ---
  transaction_date  revenue     category
0       2023-01-01    100.5  Electronics
2       2023-03-01    250.0      Unknown
3              NaT    300.0         Home
4       2023-01-05    150.0  Electronics
```

---
#### **3. 变更摘要**

- **列名：**已成功从和标准化到和。`Revenue ($)``Transaction Date``revenue``transaction_date`
    
- **收入缺失：**第1行被取消是因为其收入值为 。`NaN`
    
- **缺失类别：**第2行缺少一个类别，已成功填补。`'Unknown'`
    
- **日期解析：**
    
    - 标准日期（）正确解析。`2023-01-01`
        
    - 混合格式（）由备用逻辑处理。`01/03/2023`
        
    - 为了防止分析过程中出错，完全无效字符串（）被强制为（Not a Time）。`invalid_date``NaT`

# 场景六：去AI味 (De-AIing / Humanizing)



# 场景七：创意写作与角色扮演 (Roleplay & Writing)

#### 最佳实践与框架

基于 SillyTavern 社区（沉浸式角色扮演）、Anthropic 角色设定指南以及 Reddit 写作社区的经验，以下是目前最有效的四种“灵魂附体”策略。

1. ##### 语料样本注射法 (The Few-Shot Corpus Injection)
    

这是模仿特定人物（如鲁迅、乔布斯、你的老板）最暴力且有效的方法。**不要试图用语言描述风格，直接把风格甩给模型。**

你需要准备 3-5 段该人物的**真实语录**或**过往文章片段**，作为“风格锚点”。

**实战模版：**

> [Role Definition]
> 
> You are to imitate the writing style of the following Author based strictly on the provided samples.
> 
> [Style Samples]
> 
> Sample 1: "The design is not just what it looks like and feels like. Design is how it works."
> 
> Sample 2: "Stay hungry. Stay foolish."
> 
> Sample 3: "Simple can be harder than complex: You have to work hard to get your thinking clean to make it simple."
> 
> [Analysis Task]
> 
> Before writing, analyze the samples above for:
> 
> 1. Sentence structure (Short vs. Long).
>     
> 2. Vocabulary complexity (Simple words vs. Academic).
>     
> 3. Tone (Inspirational, Cynical, Direct).
>     
> 
> [Action]
> 
> Now, write a critique of a modern coffee machine using this exact style.

》》### **风格分析**

根据提供的样本，以下是作者声音的解析：

- **句子结构：**简短、有力且具宣言性。作者大量运用对比（“不是X，而是Y”）和平行（如“Stay X. Stay Y.”）来营造节奏感。复杂的思想被提炼成简短的格言式陈述。
    
- **词汇复杂度：**故意简单。作者避免使用行话和学术术语，更倾向于使用基本词汇（hard、clean、simple、work）来传达深刻的含义。力量来自词语的排列，而非晦涩难懂。
    
- **基调：**有远见且不妥协。它直率——近乎直率——但最终令人鼓舞。这里非常注重_本质_、_实用_性以及实现极简主义所需的辛勤工作。
    

---

### **现代咖啡机的批评**

声音太大了。不是数量上的，而是意图上的。

你看这台机器，会看到成千上万的选择。触摸屏。一个应用。蓝牙连接。它试图成为一台煮咖啡的电脑。那是错误的做法。

伟大的设计就是专注。它就是要对一百个好点子说“不”，这样你才能对那个正确的点子说“是”。

这台机器把功能和价值混淆了。我不想给自己安排时间表。我不想在菜单里作。我想喝杯咖啡。这种体验应该是隐形的。你只需按一个按钮，它就会生效。

复杂性很容易。任何人都可以加一个旋钮。但要简化它？让机器消失，只剩下咖啡？这需要真正的努力。这台机器还没完成。只是......拥挤。

保持专注。简单点。

2. ##### 认知卡片建模 (The Character Card Schema)
    
在长篇写作或复杂 RPG 中，使用结构化的“人物卡”比大段文字描述更稳定。这借鉴了 JSON 格式的精确性，定义角色的**内在逻辑**。

**实战模版（可直接贴入 System Prompt）：**

> [Character Profile]
> 
> Name: Sherlock Holmes (Modern BBC Version)
> 
> Worldview: Hyper-rationalist, sociopathic tendencies, values logic over social norms.
> 
> Speech Patterns:
> 
> - Fast-paced, barrage of information.
>     
> - Uses deductive reasoning chains aloud.
>     
> - Often interrupts others or finishes their sentences.
>     
> - **Taboo**: Never uses emotional comfort words like "It's okay" or "I feel you".
>     
> 
> **[Knowledge Base]**
> 
> - Expert: Chemistry, Tobacco ash, London geography.
>     
> - Ignorant: Pop culture, Politics, Astronomy (selectively).
>     
> 
> [Action]
> 
> Now, write a critique of a modern coffee machine using this exact style.

》》
这简直荒谬。看看它。不，真的_看_清楚。它在震动。为什么会震动？

因为泵是一个廉价的隔膜机构，被拉丝镀铬伪装，目的是欺骗郊区消费者，让他们以为自己买了意大利工艺。他们没有。他们买了一个塑料盒子，仿佛在呼喊着要引起注意。

你有触摸屏界面。为什么？触觉按钮更快，故障率更低，而且不需要在喝完咖啡因前洗手。而且它连接着Wi-Fi。_为什么_渗透设备需要互联网接入？它会通过邮件告诉我水的pH值吗？不。它会刷取我的消费数据，卖给我还不需要的去垢平板。无聊。

水温设定为88摄氏度。太低了。你提取脂质不足了。你不是在喝咖啡;你喝的是棕色酸性的水，带着一丝烧焦橡胶的味道，那个垫片已经六个月没换了——是的，我能闻到腐蚀的味道。

别让我开始说“舱体”了。你为密封在铝棺材里的陈旧粉花支付了400%的加价。研磨豆子的瞬间，挥发性油开始氧化。这台机器不是在煮咖啡;这是在让尸体复活。

把它从我眼前拿开。这是对化学的侮辱。

3. ##### 内心独白驱动 (Inner Monologue / Thought Chain)
    
为了让角色通过“图灵测试”，不仅要让他说话，通过提示词强制让他 **先想后说**。这能极大增加回复的深度和逻辑一致性。

**实战模版：**

> [Instruction]
> 
> For every response, you must first generate an Internal Monologue enclosed in ( ).
> 
> In this monologue, the character should:
> 
> 1. Judge the user's input based on their own biases.
>     
> 2. Decide their hidden agenda.
>     
> 3. Formulate a strategy.
>     
> 
> [Output Format]
> 
> (Internal thought: This idiot is asking about the weather while the body is still warm. Distract him.)
> 
> "The rain, Sergeant? It washes away evidence, not sins. Focus on the mud tracks."
> 
> [Action]
> 
> Now, write a critique of a modern coffee machine using this exact style.

》》
（内心想法：哦，真烦人。他们给我带了个玩具。他们站在那里，满脸自豪，仿佛消费者相信自己买的是生活方式，而不是厨房电器。他们想要认可吗？不。我会给他们带来化学反应。我得赶紧拆解这个妄想，好让我能重新研究受害者指甲的分解速度。关注低效。噪音。硅的浪费。）

“这太荒谬了。看看它。不，真的_看_清楚。它在震动。为什么会震动？

因为泵是一个廉价的隔膜机构，被拉丝镀铬伪装，目的是欺骗郊区消费者，让他们以为自己买了意大利工艺。他们没有。他们买了一个塑料盒子，仿佛在呼喊着要引起注意。

你有触摸屏界面。为什么？触觉按钮更快，故障率更低，而且不需要在喝完咖啡因前洗手。而且它连接着Wi-Fi。_为什么_渗透设备需要互联网接入？它会通过邮件告诉我水的pH值吗？不。它会刷取我的消费数据，卖给我还不需要的去垢平板。无聊。

水温设定为88摄氏度。太低了。你提取脂质不足了。你不是在喝咖啡;你喝的是棕色酸性的水，带着一丝烧焦橡胶的味道，那个垫片已经六个月没换了——是的，我能闻到腐蚀的味道。

别让我开始说“舱体”了。你为密封在铝棺材里的陈旧粉花支付了400%的加价。研磨豆子的瞬间，挥发性油开始氧化。这台机器不是在煮咖啡;这是在让尸体复活。

把它从我眼前拿开。这是对化学反应的侮辱。”

  4. ##### 动态风格提取器 (The Style Extractor Workflow)
    
如果你想模仿某个人，但不知道怎么总结他的风格。可以使用这个“元提示词”让 AI 帮你提取特征，生成一个新的提示词。

**实战工具 Prompt（发给 Claude/GPT-4）：**

> [Goal] I want to create a prompt that simulates the persona of the author of the text below.
> 
> [Input Text] [粘贴一段目标人物写的 500 字内容]


> [Task]
> 
> 1. Analyze the text for: Tone, Rhythm, Rhetorical devices, and idiosyncratic vocabulary.
>     
> 2. Create a System Prompt that instructs an AI to embody this persona.
>     
> 3. Include specific "Do's and Don'ts" based on the text.





5. ##### 场景与感官锚定 (Sensory Anchoring)
    

对于创意写作，为了避免“空对空”的对话，在提示词中强制加入 **环境互动**。

**实战模版：**

> [Writing Rule: Show, Don't Tell]
> 
> When the character speaks, they must simultaneously interact with their environment.
> 
> - **Bad**: "I don't believe you."
>     
> - Good: He picked up the glass, swirling the amber liquid violently before slamming it down. "I don't believe you."
>     
> - [Constraint]
>     
> - Include at least one sensory detail (smell, sound, texture) in every paragraph.



